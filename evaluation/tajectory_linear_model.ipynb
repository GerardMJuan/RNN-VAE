{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific patient trajectory and linear model\n",
    "Scripts and methods to plot trajectories for specific patients and compare it to a linear regression model.\n",
    "\n",
    "This script does:\n",
    "\n",
    "1. Plots trajectories of specific patients at different diagnosis (CN, MCI, AD). \n",
    "2. plot trajectories of patients that convert.\n",
    "3. Do prediction with a linear model on a small unseen set of patients at different diagnosis, for future times. Show predictions for future, known times.\n",
    "4. Do the same prediction with a good trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homedtic/gmarti/CODE/RNN-VAE\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "# working dir\n",
    "%cd /homedtic/gmarti/CODE/RNN-VAE/\n",
    "\n",
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(0, '/homedtic/gmarti/CODE/RNN-VAE/')\n",
    "from rnnvae.utils import open_MRI_data_var\n",
    "from rnnvae import rnnvae\n",
    "from rnnvae.plot import plot_losses, plot_trajectory, plot_total_loss, plot_z_2d, plot_z_time_2d\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE\n",
    "## Decidint on device on device.\n",
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device('cuda:' + str(DEVICE_ID) if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE_ID)\n",
    "\n",
    "# out_dir = \"experiments/MRI_padding_lin_mask/\"\n",
    "out_dir = \"experiments/meta_cort/_h_40_z_7_hid_40_l_1/\"\n",
    "\n",
    "#load parameters\n",
    "p = eval(open(out_dir + \"params.txt\").read())\n",
    "\n",
    "#Seed\n",
    "torch.manual_seed(p[\"seed\"])\n",
    "np.random.seed(p[\"seed\"])\n",
    "\n",
    "p['x_size'] = 68\n",
    "\n",
    "model = rnnvae.ModelRNNVAE(p[\"x_size\"], p[\"h_size\"], p[\"hidden\"], p[\"n_layers\"], \n",
    "                        p[\"hidden\"], p[\"n_layers\"], p[\"hidden\"],\n",
    "                        p[\"n_layers\"], p[\"z_dim\"], p[\"hidden\"], p[\"n_layers\"],\n",
    "                        p[\"clip\"], p[\"n_epochs\"], p[\"batch_size\"], DEVICE)\n",
    "model.load(out_dir+'model.pt')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a specific value, generate it for a given number of timepoints and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b04d426e625d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Those datasets are of size [Tmax, Batch_size, nfeatures]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Predict the reconstructions from X_val and X_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mX_test_fwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mX_train_fwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;31m# Convert to numpy the xnext and the zx values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;31m#HERE, SELECT ONLY THE MASK CORRESPONDING TO THAT TIME POINT (MAYBE A ZIP?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mxnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzp_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqzx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpxz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             \u001b[0;31m#xnext or x_t?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xt, ht)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m##### ENCODER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mx_phi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;31m# Append both inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_phi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "csv_path = \"data/tadpole_cortonly.csv\"\n",
    "X_train, X_test, Y_train, Y_test, mri_col = open_MRI_data_var(csv_path, train_set=0.9, normalize=True, return_covariates=True)\n",
    "\n",
    "nfeatures = X_train[0].shape[1]\n",
    "\n",
    "# Apply padding to both X_train and X_val\n",
    "X_train_tensor = [ torch.FloatTensor(t) for t in X_train ]\n",
    "X_train_pad = torch.nn.utils.rnn.pad_sequence(X_train_tensor, batch_first=False, padding_value=np.nan)\n",
    "X_test_tensor = [ torch.FloatTensor(t) for t in X_test ]\n",
    "X_test_pad = torch.nn.utils.rnn.pad_sequence(X_test_tensor, batch_first=False, padding_value=np.nan)\n",
    "\n",
    "# Those datasets are of size [Tmax, Batch_size, nfeatures]\n",
    "mask_train = ~torch.isnan(X_train_pad)\n",
    "mask_test = ~torch.isnan(X_test_pad)\n",
    "\n",
    "#convert those NaN to zeros\n",
    "X_train_pad[torch.isnan(X_train_pad)] = 0\n",
    "X_test_pad[torch.isnan(X_test_pad)] = 0\n",
    "\n",
    "max_timepoints = X_train_pad.shape[0]\n",
    "# Those datasets are of size [Tmax, Batch_size, nfeatures]\n",
    "# Predict the reconstructions from X_val and X_train\n",
    "X_test_fwd = model.predict(X_test_pad.to(DEVICE))\n",
    "X_train_fwd = model.predict(X_train_pad.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_pad.shape)\n",
    "print(len(mri_col))\n",
    "print(mri_col)\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get specific patients that we want to study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define patients\n",
    "# Select the patients from the csv, and see if they are present on the training set\n",
    "#Candidats:\n",
    "#CN: 007_S_0068, 002_S_0295\n",
    "#MCI: 136_S_0107\n",
    "#AD: 116_S_0487\n",
    "#Convert MCI to dementia: 007_S_0344. Converteix a m12, el segon timepoint\n",
    "PTID_CN = \"002_S_0295\"\n",
    "PTID_MCI = \"136_S_0107\"\n",
    "PTID_AD = \"116_S_0487\"\n",
    "PTID_CONVERT = \"007_S_0344\"\n",
    "\n",
    "# Compare only baseline\n",
    "patient_index = [i for i, x in enumerate(Y_train[\"PTID\"]) if x[0] == PTID_CONVERT][0]\n",
    "#still list of one patient\n",
    "patient = [X_train[patient_index]]\n",
    "\n",
    "#ntp train will always be length of the patient minus 1 or 2\n",
    "#ntp predict will always be the actual full length of the project\n",
    "ntp_train = patient[0].shape[0] - 1\n",
    "ntp_predict = patient[0].shape[0]\n",
    "\n",
    "patient_to_train = [patient[0][:ntp_train, :]]\n",
    "\n",
    "# Select the feature. We would like to select a feature like the hippocampus or similar\n",
    "feat = 36\n",
    "feat_name = mri_col[feat]\n",
    "print(feat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Linear regression for those specific patients, and predict next values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear model\n",
    "X_lin = np.array(range(ntp_train)).reshape(-1, 1) # X is the time points\n",
    "Y_lin = patient_to_train[0]\n",
    "print(X_lin.shape)\n",
    "print(Y_lin.shape)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_lin, Y_lin)\n",
    "Y_lin_pred = linreg.predict(np.array(range(ntp_predict)).reshape(-1, 1))\n",
    "print(Y_lin_pred.shape)\n",
    "\n",
    "plt.plot(X_lin, Y_lin[:, feat], '-b', label='X (Original)')\n",
    "#Plot all the objective points\n",
    "for i in range(ntp_train, ntp_predict):\n",
    "    plt.plot(i, patient[0][i,feat], 'xb', label='X (to predict)')\n",
    "plt.plot(list(range(ntp_predict)), Y_lin_pred[:, feat], '-r', label='X (predicted)')\n",
    "for i in range(ntp_predict):\n",
    "    plt.plot(i, Y_lin_pred[i,feat], 'xr')\n",
    "\n",
    "plt.xlabel(\"time-point\")\n",
    "plt.ylabel(\"value\")\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.title(\"Linear regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN VAE\n",
    "#Get tensor for a single subject\n",
    "# REMEMBER TO PERMUTE, FIRST DIMENSIONS IS TIME!\n",
    "patient_tensor = torch.FloatTensor(patient_to_train).permute((1,0,2))\n",
    "X_fwd = model.sequence_predict(patient_tensor.to(DEVICE), ntp_predict)\n",
    "\n",
    "#Get prediction\n",
    "X_hat = X_fwd[\"xnext\"]\n",
    "print(patient_tensor.shape)\n",
    "print(X_hat.shape)\n",
    "X_hat_line = X_hat[:, 0, feat]   #Select only the subject we want\n",
    "X_samples_line = patient_tensor[:, 0, feat].numpy()   #Select only the subject we want\n",
    "print(X_hat_line.shape)\n",
    "print(X_samples_line.shape)\n",
    "# Plot the two lines\n",
    "plt.figure()\n",
    "plt.plot(range(len(X_hat_line)), X_hat_line, '-r', label='X (predicted)')\n",
    "plt.plot(range(len(X_samples_line)), X_samples_line, '-b', label='X (original)')\n",
    "for i in range(ntp_train, ntp_predict):\n",
    "    plt.plot(i, patient[0][i,feat], 'xb', label='X (to predict)')\n",
    "\n",
    "plt.xlabel(\"time-point\")\n",
    "plt.ylabel(\"value\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(\"Predicted vs real\")\n",
    "\n",
    "#Resultats bastant lamentables..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized prediction\n",
    "For all subjects, predict the last value, using both a linear model (for each patient) and the RNN-VAE model (fit it here too). Then, predict the last time-point for each patient,\n",
    "and compute a loss (rmse loss?) over all the predicted values. This way, we would see how the model works and do a major comparison on that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "n_to_predict = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error linear model: 0.4699439642525517\n"
     ]
    }
   ],
   "source": [
    "##Generalized prediction using linear model\n",
    "# One linear model per subject\n",
    "Y_pred = []\n",
    "Y_true = []\n",
    "\n",
    "#Compute the models and predictions\n",
    "for p in X_train:\n",
    "    ntp_train = p.shape[0]-n_to_predict\n",
    "    if ntp_train == 0:\n",
    "        continue\n",
    "    X_lin = np.array(range(ntp_train)).reshape(-1, 1) # X is the time points\n",
    "    Y_lin = p[:ntp_train, :]\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_lin, Y_lin)\n",
    "    Y_lin_pred = linreg.predict(np.array(range(ntp_predict)).reshape(-1, 1))\n",
    "    # Select original and y_lin_pred last point, and append it \n",
    "    Y_true.append(p[-1, :])\n",
    "    Y_pred.append(Y_lin_pred[-1, :])\n",
    "\n",
    "#Compute mse\n",
    "mse_linear = mean_squared_error(Y_true, Y_pred)\n",
    "print(f'Mean Squared Error linear model: {mse_linear}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,)\n",
      "(40,)\n",
      "Mean Squared Error linear model: 0.3683970790060767\n"
     ]
    }
   ],
   "source": [
    "# Predict for max+1 and select only the positions that I am interested in\n",
    "#this sequence predict DO NOT work well\n",
    "Y_true = []\n",
    "Y_pred = []\n",
    "\n",
    "for i in range(X_train_pad.size(1)):\n",
    "    x = torch.FloatTensor(X_train[i][:-n_to_predict,:])\n",
    "    x = x.unsqueeze(1)\n",
    "    tp = x.size(0) # max time points (and timepoint to predict)\n",
    "    if tp == 0:\n",
    "        continue\n",
    "    X_fwd = model.sequence_predict(x.to(DEVICE), tp+1)\n",
    "    X_hat = X_fwd['xnext']\n",
    "    Y_pred.append(X_hat[tp, 0, :]) #get predicted point\n",
    "    Y_true.append(X_train[i][-1,:])\n",
    "print(Y_true[0].shape)\n",
    "print(Y_pred[0].shape)\n",
    "    \n",
    "#For each patient in X_hat, saveonly the timepoint that we want\n",
    "#Compute mse\n",
    "mse_linear = mean_squared_error(Y_true, Y_pred)\n",
    "print(f'Mean Squared Error linear model: {mse_linear}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 792, 40])\n",
      "Train loss Epoch:    0/1000 (0%)\tLoss: 519.3767\tLL: -516.6365\tKL: 2.7402\tLL/KL: -188.5421\n",
      "Validation loss Epoch:    0/1000 (0%)\tLoss: 443.9859\tLL: -442.0950\tKL: 1.8909\tLL/KL: -233.8074\n",
      "Train loss Epoch:  100/1000 (10%)\tLoss: 246.7952\tLL: -229.4583\tKL: 17.3370\tLL/KL: -13.2352\n",
      "Validation loss Epoch:  100/1000 (10%)\tLoss: 328.6924\tLL: -314.9983\tKL: 13.6942\tLL/KL: -23.0024\n",
      "Train loss Epoch:  200/1000 (20%)\tLoss: 122.4648\tLL: -100.7164\tKL: 21.7484\tLL/KL: -4.6310\n",
      "Validation loss Epoch:  200/1000 (20%)\tLoss: 296.1040\tLL: -277.0412\tKL: 19.0628\tLL/KL: -14.5331\n",
      "Train loss Epoch:  300/1000 (30%)\tLoss: 77.3226\tLL: -55.9120\tKL: 21.4106\tLL/KL: -2.6114\n",
      "Validation loss Epoch:  300/1000 (30%)\tLoss: 281.3371\tLL: -260.9074\tKL: 20.4297\tLL/KL: -12.7710\n",
      "Train loss Epoch:  400/1000 (40%)\tLoss: 39.2923\tLL: -16.2076\tKL: 23.0847\tLL/KL: -0.7021\n",
      "Validation loss Epoch:  400/1000 (40%)\tLoss: 282.7305\tLL: -260.5299\tKL: 22.2006\tLL/KL: -11.7353\n",
      "Train loss Epoch:  500/1000 (50%)\tLoss: 20.5247\tLL: 3.9118\tKL: 24.4364\tLL/KL: 0.1601\n",
      "Validation loss Epoch:  500/1000 (50%)\tLoss: 288.9590\tLL: -265.3385\tKL: 23.6205\tLL/KL: -11.2334\n",
      "Train loss Epoch:  600/1000 (60%)\tLoss: 9.2279\tLL: 14.2619\tKL: 23.4898\tLL/KL: 0.6072\n",
      "Validation loss Epoch:  600/1000 (60%)\tLoss: 298.1178\tLL: -273.6357\tKL: 24.4820\tLL/KL: -11.1770\n",
      "Train loss Epoch:  700/1000 (70%)\tLoss: -6.9808\tLL: 29.5976\tKL: 22.6168\tLL/KL: 1.3087\n",
      "Validation loss Epoch:  700/1000 (70%)\tLoss: 313.3886\tLL: -287.7086\tKL: 25.6801\tLL/KL: -11.2036\n",
      "Train loss Epoch:  800/1000 (80%)\tLoss: -13.8796\tLL: 37.6667\tKL: 23.7871\tLL/KL: 1.5835\n",
      "Validation loss Epoch:  800/1000 (80%)\tLoss: 320.8054\tLL: -294.7566\tKL: 26.0487\tLL/KL: -11.3156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-efbd05525b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_train_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmask_test_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data_train, data_val, mask_train, mask_val)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# Check loss nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mfit_batch\u001b[0;34m(self, x_batch, mask)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mFunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mof\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \"\"\"\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;31m#HERE, SELECT ONLY THE MASK CORRESPONDING TO THAT TIME POINT (MAYBE A ZIP?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mxnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzp_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqzx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpxz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             \u001b[0;31m#xnext or x_t?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xt, ht)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_phi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# Run through the encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mqzx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m#Sample from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/rnnvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_logvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         x = Normal(\n\u001b[1;32m    137\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                 self._forward_hooks.values()):\n\u001b[0m\u001b[1;32m    726\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load parameters\n",
    "p = eval(open(out_dir + \"params.txt\").read())\n",
    "p['x_size'] = 40\n",
    "\n",
    "##Generalized prediction using RNNVAE\n",
    "#One general model, and then full prediction\n",
    "\n",
    "# For the train dataset, we can remove the last timepoint\n",
    "X_train_tensor = [ torch.FloatTensor(t[:-n_to_predict,:]) for t in X_train ]\n",
    "X_train_pad = torch.nn.utils.rnn.pad_sequence(X_train_tensor, batch_first=False, padding_value=np.nan)\n",
    "\n",
    "# no need to do the same on the test set\n",
    "X_test_tensor = [ torch.FloatTensor(t) for t in X_test ]\n",
    "X_test_pad = torch.nn.utils.rnn.pad_sequence(X_test_tensor, batch_first=False, padding_value=np.nan)\n",
    "\n",
    "# Those datasets are of size [Tmax, Batch_size, nfeatures]\n",
    "# Save mask to unpad later when testing\n",
    "mask_train = ~torch.isnan(X_train_pad)\n",
    "mask_test = ~torch.isnan(X_test_pad)\n",
    "\n",
    "mask_train_tensor = torch.BoolTensor(mask_train)\n",
    "mask_test_tensor = torch.BoolTensor(mask_test)\n",
    "\n",
    "#convert those NaN to zeros\n",
    "X_train_pad[torch.isnan(X_train_pad)] = 0\n",
    "X_test_pad[torch.isnan(X_test_pad)] = 0\n",
    "\n",
    "X_train_pad[torch.isnan(X_train_pad)] = 0\n",
    "\n",
    "max_timepoints = X_train_pad.shape[0]\n",
    "print(X_train_pad.shape)\n",
    "\n",
    "# Define model and optimizer\n",
    "\n",
    "model = rnnvae.ModelRNNVAE(p[\"x_size\"], p[\"h_size\"], p[\"hidden\"], p[\"n_layers\"], \n",
    "                        p[\"hidden\"], p[\"n_layers\"], p[\"hidden\"],\n",
    "                        p[\"n_layers\"], p[\"z_dim\"], p[\"hidden\"], p[\"n_layers\"],\n",
    "                        p[\"clip\"], p[\"n_epochs\"], p[\"batch_size\"], DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=p[\"learning_rate\"])\n",
    "model.optimizer = optimizer\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_pad.to(DEVICE), X_test_pad.to(DEVICE), mask_train_tensor.to(DEVICE),  mask_test_tensor.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0][:-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
