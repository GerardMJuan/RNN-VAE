{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent visualization: Synth data\n",
    "Do the visualization of the new data and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homedtic/gmarti/CODE/RNN-VAE\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "# working dir\n",
    "%cd /homedtic/gmarti/CODE/RNN-VAE/\n",
    "\n",
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(0, '/homedtic/gmarti/CODE/RNN-VAE/')\n",
    "from rnnvae.utils import open_MRI_data_var\n",
    "from rnnvae import rnnvae_h\n",
    "from rnnvae.plot import plot_losses, plot_trajectory, plot_total_loss, plot_z_2d, plot_z_time_2d, plot_latent_space\n",
    "import os\n",
    "import math\n",
    "from rnnvae.data_gen import LatentDataGeneratorCurves\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "[[('sigmoid', {'L': 1, 'k': 10, 'x0': 5}), ('sigmoid', {'L': 1, 'k': 10, 'x0': 5}), ('sigmoid', {'L': 1, 'k': 10, 'x0': 5})], [('sigmoid', {'L': 1, 'k': -5, 'x0': 3}), ('sigmoid', {'L': 1, 'k': -5, 'x0': 3}), ('sigmoid', {'L': 1, 'k': -5, 'x0': 3})], [('sigmoid', {'L': 1, 'k': -15, 'x0': 1}), ('sigmoid', {'L': 1, 'k': -15, 'x0': 1}), ('sigmoid', {'L': 1, 'k': -15, 'x0': 1})]]\n"
     ]
    }
   ],
   "source": [
    "# DEVICE\n",
    "## Decidint on device on device.\n",
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device('cuda:' + str(DEVICE_ID) if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE_ID)\n",
    "\n",
    "print(DEVICE)\n",
    "\n",
    "out_dir = \"/homedtic/gmarti/EXPERIMENTS_MCVAE/synth_testing/\"\n",
    "\n",
    "#load parameters\n",
    "p = eval(open(out_dir + \"params.txt\").read())\n",
    "print(p['curves'])\n",
    "\n",
    "# data parameters\n",
    "ntp = 10\n",
    "noise = 0.1\n",
    "variable_tp=False\n",
    "lat_dim=2\n",
    "n_channels=3\n",
    "n_feats=10\n",
    "n_samples=200\n",
    "\n",
    "ch_type = [\"long\", \"long\", \"long\"]\n",
    "\n",
    "model = rnnvae_h.MCRNNVAE(p[\"h_size\"], p[\"x_hidden\"], p[\"x_n_layers\"], \n",
    "                        p[\"z_hidden\"], p[\"z_n_layers\"], p[\"enc_hidden\"],\n",
    "                        p[\"enc_n_layers\"], p[\"z_dim\"], p[\"dec_hidden\"], p[\"dec_n_layers\"],\n",
    "                        p[\"clip\"], p[\"n_epochs\"], p[\"batch_size\"], \n",
    "                        p[\"n_channels\"], p[\"ch_type\"], p[\"n_feats\"], p[\"c_z\"], DEVICE, print_every=100, \n",
    "                        phi_layers=p[\"phi_layers\"], sigmoid_mean=p[\"sig_mean\"],\n",
    "                        dropout=p[\"dropout\"], dropout_threshold=p[\"drop_th\"])\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "model.load(out_dir+'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-14da4f424221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Generate data, with different parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlat_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDataGeneratorCurves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"curves\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlat_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CODE/RNN-VAE/rnnvae/data_gen.py\u001b[0m in \u001b[0;36mgenerate_samples\u001b[0;34m(self, nsamples)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mcurve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;31m#for the number of features indicated in that curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurve_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurve\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurve\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mch_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bl'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "# Test reconstruction of samples\n",
    "#Generate data, with different parameters\n",
    "lat_gen = LatentDataGeneratorCurves(p[\"curves\"], ch_type, ntp, noise, lat_dim, n_channels, n_feats)\n",
    "X = lat_gen.generate_samples(n_samples)\n",
    "\n",
    "\n",
    "X_train_list = []\n",
    "X_samples_notensor = []\n",
    "mask_train_list = []\n",
    "\n",
    "#generate the data, and the mask corresponding to each channel\n",
    "for x_ch in X:\n",
    "    #originally, x_ch is ntp, nfeat, nsamples\n",
    "    #  should be size nsamples, ntp, nfeat\n",
    "    #x_ch = x_ch.swapaxes(0,2).swapaxes(1,2)\n",
    "    X_train_tensor = [ torch.FloatTensor(t) for t in x_ch ]\n",
    "    X_train_pad_i = nn.utils.rnn.pad_sequence(X_train_tensor, batch_first=False, padding_value=np.nan)\n",
    "    mask_train = ~torch.isnan(X_train_pad_i)\n",
    "    mask_train_list.append(mask_train.to(DEVICE))\n",
    "    X_train_pad_i[torch.isnan(X_train_pad_i)] = 0\n",
    "    X_train_list.append(X_train_pad_i.to(DEVICE))\n",
    "    X_samples_notensor.append(x_ch)\n",
    "\n",
    "# Predict the reconstructions from X_val and X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fwd = model.predict(X_train_list, mask_train_list, nt=ntp)\n",
    "\n",
    "#Reformulate things\n",
    "X_pred = [np.array(x).swapaxes(0,1) for x in X_fwd['xnext']]\n",
    "\n",
    "print(len(X_pred))\n",
    "print(X_pred[0].shape)\n",
    "\n",
    "print(len(X_samples_notensor))\n",
    "print(len(X_samples_notensor[0]))\n",
    "print(len(X_samples_notensor[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict reconstruction\n",
    "ch_list = [0,1,2]\n",
    "\n",
    "recon_ch = []\n",
    "\n",
    "for ch in ch_list:\n",
    "    av_ch = [0,1,2]\n",
    "    av_ch.remove(ch)\n",
    "    print(av_ch)\n",
    "    # Predict the reconstructions from X_val and X_train\n",
    "    X_fwd = model.predict(X_train_list, mask_train_list, nt=ntp, av_ch=av_ch, task='recon')\n",
    "\n",
    "    #Reformulate things\n",
    "    X_fwd = [np.array(x).swapaxes(0,1) for x in X_fwd['xnext']]\n",
    "    recon_ch.append(X_fwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidates 57\n",
    "subj = 57\n",
    "feat = 2\n",
    "sns.set()\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(12,8), sharex=False, sharey=False)\n",
    "## Create figures of three signals and their points, with a subplots and everything\n",
    "ch_feats = [0,1,2]\n",
    "axes = [ax1,ax2,ax3]\n",
    "#Plot full reconstruction\n",
    "for (ch, ax) in zip(ch_feats, axes):\n",
    "\n",
    "    X_hat_line = X_pred[ch][subj][:, feat]   #Select only the subject we want\n",
    "    X_samples_line = X_samples_notensor[ch][subj][:, feat]   #Select only the subject we want\n",
    "\n",
    "    # Plot the two lines\n",
    "    ax.plot(range(len(X_hat_line)), X_hat_line, '-b', label='X (predicted)')\n",
    "    ax.plot(range(len(X_samples_line)), X_samples_line, '-r', label='X (original)')\n",
    "\n",
    "    #ax.set_xlabel('time-point')\n",
    "    #ax.xlabel(\"time-point\")\n",
    "    #ax.ylabel(\"value\")\n",
    "    #ax.set_xticklabels([])\n",
    "    #ax.set_yticklabels([])\n",
    "\n",
    "#Plot full reconstruction\n",
    "axes = [ax4,ax5,ax6]\n",
    "for (ch, ax) in zip(ch_feats, axes):\n",
    "\n",
    "    X_hat_line = recon_ch[ch][ch][subj][:, feat]   #Select only the subject we want\n",
    "    X_samples_line = X_samples_notensor[ch][subj][:, feat]   #Select only the subject we want\n",
    "\n",
    "    # Plot the two lines\n",
    "    ax.plot(range(len(X_hat_line)), X_hat_line, '-b', label='X (predicted)')\n",
    "    ax.plot(range(len(X_samples_line)), X_samples_line, '-r', label='X (original)')\n",
    "\n",
    "    #ax.set_xlabel('time-point')\n",
    "    #ax.xlabel(\"time-point\")\n",
    "    #ax.ylabel(\"value\")\n",
    "    #ax.set_xticklabels([])\n",
    "    #ax.set_yticklabels([])\n",
    "\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.set_title(\"Prediction\", fontsize=15)\n",
    "ax5.set_title(\"Reconstruct from other channels\",fontsize=15)\n",
    "#plt.title(\"Predicted vs real\")\n",
    "# plt.show()\n",
    "plt.savefig(\"fig_gen/synth_recon.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create figures for latent dropout\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 3), sharex=False, sharey=True)\n",
    "\n",
    "#load the three models\n",
    "out_dir_2lat = \"synth_final_tests/test_synth_mc_dropout2/\"\n",
    "p = eval(open(out_dir_2lat + \"params.txt\").read())\n",
    "model2 = rnnvae_h.MCRNNVAE(p[\"h_size\"], p[\"hidden\"], p[\"n_layers\"], \n",
    "                        p[\"hidden\"], p[\"n_layers\"], p[\"hidden\"],\n",
    "                        p[\"n_layers\"], p[\"z_dim\"], p[\"hidden\"], p[\"n_layers\"],\n",
    "                        p[\"clip\"], p[\"n_epochs\"], p[\"batch_size\"], \n",
    "                        p[\"n_channels\"], p[\"ch_type\"], p[\"n_feats\"], DEVICE, print_every=100, \n",
    "                        phi_layers=p[\"phi_layers\"], sigmoid_mean=p[\"sig_mean\"],\n",
    "                        dropout=p[\"dropout\"], dropout_threshold=p[\"drop_th\"])\n",
    "model2.load(out_dir_2lat+'model.pt')\n",
    "dropout2 = model2.dropout_comp\n",
    "                                    \n",
    "#load parameters\n",
    "out_dir_4lat = \"synth_final_tests/test_synth_mc_dropout4/\"\n",
    "p = eval(open(out_dir_4lat + \"params.txt\").read())\n",
    "model4 = rnnvae_h.MCRNNVAE(p[\"h_size\"], p[\"hidden\"], p[\"n_layers\"], \n",
    "                        p[\"hidden\"], p[\"n_layers\"], p[\"hidden\"],\n",
    "                        p[\"n_layers\"], p[\"z_dim\"], p[\"hidden\"], p[\"n_layers\"],\n",
    "                        p[\"clip\"], p[\"n_epochs\"], p[\"batch_size\"], \n",
    "                        p[\"n_channels\"], p[\"ch_type\"], p[\"n_feats\"], DEVICE, print_every=100, \n",
    "                        phi_layers=p[\"phi_layers\"], sigmoid_mean=p[\"sig_mean\"],\n",
    "                        dropout=p[\"dropout\"], dropout_threshold=p[\"drop_th\"])\n",
    "model4.load(out_dir_4lat+'model.pt')\n",
    "dropout4 = model4.dropout_comp\n",
    "                                    \n",
    "#load parameters\n",
    "out_dir_6lat = \"synth_final_tests/test_synth_mc_dropout6/\"\n",
    "p = eval(open(out_dir_6lat + \"params.txt\").read())\n",
    "model6 = rnnvae_h.MCRNNVAE(p[\"h_size\"], p[\"hidden\"], p[\"n_layers\"], \n",
    "                        p[\"hidden\"], p[\"n_layers\"], p[\"hidden\"],\n",
    "                        p[\"n_layers\"], p[\"z_dim\"], p[\"hidden\"], p[\"n_layers\"],\n",
    "                        p[\"clip\"], p[\"n_epochs\"], p[\"batch_size\"], \n",
    "                        p[\"n_channels\"], p[\"ch_type\"], p[\"n_feats\"], DEVICE, print_every=100, \n",
    "                        phi_layers=p[\"phi_layers\"], sigmoid_mean=p[\"sig_mean\"],\n",
    "                        dropout=p[\"dropout\"], dropout_threshold=p[\"drop_th\"])\n",
    "model6.load(out_dir_6lat+'model.pt')\n",
    "dropout6 = model6.dropout_comp\n",
    "\n",
    "#sort the dropouts\n",
    "dropout2 = np.sort(dropout2).squeeze()\n",
    "dropout4 = np.sort(dropout4).squeeze()\n",
    "dropout6 = np.sort(dropout6).squeeze()\n",
    "# plot each\n",
    "sns.barplot(x=list(range(len(dropout2))), y=dropout2, color=\"royalblue\", ax=ax1)\n",
    "sns.barplot(x=list(range(len(dropout4))), y=dropout4, color=\"royalblue\", ax=ax2)\n",
    "sns.barplot(x=list(range(len(dropout6))), y=dropout6, color=\"royalblue\", ax=ax3)\n",
    "\n",
    "# plot lines\n",
    "ax1.axhline(0.2, ls='--', c='black')\n",
    "ax2.axhline(0.2, ls='--', c='black')\n",
    "ax3.axhline(0.2, ls='--', c='black')\n",
    "\n",
    "ax1.set_ylabel(\"Dropout\", fontsize=16)\n",
    "ax1.set_xlabel(\"z dim.\", fontsize=16)\n",
    "ax2.set_xlabel(\"z dim.\", fontsize=16)\n",
    "ax3.set_xlabel(\"z dim.\", fontsize=16)\n",
    "\n",
    "ax1.set_title(\"$l=2$\", fontsize=16)\n",
    "ax2.set_title(\"$l=4$\", fontsize=16)\n",
    "ax3.set_title(\"$l=6$\", fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_gen/synthvardrop.pdf\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
