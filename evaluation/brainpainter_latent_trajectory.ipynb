{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainpainter latent trajectory\n",
    "\n",
    "Draw a trajectory over the latent space with a set of parameters and translate it to a BrainPainter ready file in order\n",
    "to visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homedtic/gmarti/CODE/RNN-VAE\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "# working dir\n",
    "%cd /homedtic/gmarti/CODE/RNN-VAE/\n",
    "\n",
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(0, '/homedtic/gmarti/CODE/RNN-VAE/')\n",
    "from rnnvae.utils import open_MRI_data_var, open_MRI_data\n",
    "from rnnvae import rnnvae\n",
    "from rnnvae.plot import plot_losses, plot_trajectory, plot_total_loss, plot_z_2d, plot_z_time_2d\n",
    "import os\n",
    "import math\n",
    "from rnnvae.data_gen import SinDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from the experiment and directory we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE\n",
    "## Decidint on device on device.\n",
    "DEVICE_ID = 0\n",
    "DEVICE = torch.device('cuda:' + str(DEVICE_ID) if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE_ID)\n",
    "\n",
    "out_dir = \"experiments/meta_mri_noicv/_h_40_z_7_hid_40_l_1/\"\n",
    "\n",
    "#load parameters\n",
    "p = eval(open(out_dir + \"params.txt\").read())\n",
    "\n",
    "p['x_size'] = 40\n",
    "\n",
    "model = rnnvae.ModelRNNVAE(p[\"x_size\"], p[\"h_size\"], p[\"hidden\"], p[\"n_layers\"], \n",
    "                        p[\"hidden\"], p[\"n_layers\"], p[\"hidden\"],\n",
    "                        p[\"n_layers\"], p[\"z_dim\"], p[\"hidden\"], p[\"n_layers\"],\n",
    "                        p[\"clip\"], p[\"n_epochs\"], p[\"batch_size\"], DEVICE)\n",
    "model.load(out_dir+'model.pt')\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-208dc7832340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_fwd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mz_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-208dc7832340>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_fwd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mz_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z_dim' is not defined"
     ]
    }
   ],
   "source": [
    "csv_path = \"data/tadpole_mrionly.csv\"\n",
    "X_train, X_test, Y_train, Y_test, mri_col = open_MRI_data_var(csv_path, train_set=0.9, normalize=True, return_covariates=True)\n",
    "\n",
    "nfeatures = X_train[0].shape[1]\n",
    "\n",
    "# Apply padding to both X_train and X_val\n",
    "X_train_tensor = [ torch.FloatTensor(t) for t in X_train ]\n",
    "X_train_pad = torch.nn.utils.rnn.pad_sequence(X_train_tensor, batch_first=False, padding_value=np.nan)\n",
    "X_test_tensor = [ torch.FloatTensor(t) for t in X_test ]\n",
    "X_test_pad = torch.nn.utils.rnn.pad_sequence(X_test_tensor, batch_first=False, padding_value=np.nan)\n",
    "\n",
    "# Those datasets are of size [Tmax, Batch_size, nfeatures]\n",
    "mask_train = ~torch.isnan(X_train_pad)\n",
    "mask_test = ~torch.isnan(X_test_pad)\n",
    "\n",
    "#convert those NaN to zeros\n",
    "X_train_pad[torch.isnan(X_train_pad)] = 0\n",
    "X_test_pad[torch.isnan(X_test_pad)] = 0\n",
    "\n",
    "max_timepoints = X_train_pad.shape[0]\n",
    "# Those datasets are of size [Tmax, Batch_size, nfeatures]\n",
    "# Predict the reconstructions from X_val and X_train\n",
    "X_test_fwd = model.predict(X_test_pad.to(DEVICE))\n",
    "X_train_fwd = model.predict(X_train_pad.to(DEVICE))\n",
    "\n",
    "#Reshape features so that nsubjects go first\n",
    "X_train_hat = np.array(X_train_fwd['xnext']).swapaxes(0,1)\n",
    "z_train = np.array(X_train_fwd['z']).swapaxes(0,1)\n",
    "X_test_hat = np.array(X_test_fwd['xnext']).swapaxes(0,1)\n",
    "z_test = np.array(X_test_fwd['z']).swapaxes(0,1)\n",
    "\n",
    "z_train = [Z[mask_train[:,i,:p['z_dim']]].reshape((-1, p['z_dim'])) for (i, Z) in enumerate(z_train)]\n",
    "z_test = [Z[mask_test[:,i,:p['z_dim']]].reshape((-1, p['z_dim'])) for (i, Z) in enumerate(z_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 2D Trajectory latent space visualization\n",
    "dim0=0\n",
    "dim1=1\n",
    "\n",
    "#This needs to be colored by DX and AGE, and \n",
    "\n",
    "#plot_z_time_2d(z, max_timepoints, [dim0, dim1], out_dir, out_name='latent_space_2d')\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# create color cmap\n",
    "colors = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "#Pallete for dx\n",
    "colors = sns.color_palette([\"#2a9e1e\", \"#bfbc1a\", \"#af1f1f\"])\n",
    "# sns.set_palette(colors)\n",
    "\n",
    "z_d0_full = []\n",
    "z_d1_full = []\n",
    "tp_full = []\n",
    "color = []\n",
    "\n",
    "# Create dictionary of the different labels\n",
    "dx_dict = {\n",
    "    \"NL\": \"CN\",\n",
    "    \"MCI\": \"MCI\",\n",
    "    \"MCI to NL\": \"CN\",\n",
    "    \"Dementia\": \"AD\",\n",
    "    \"Dementia to MCI\": \"MCI\",\n",
    "    \"NL to MCI\": \"MCI\",\n",
    "    \"MCI to Dementia\": \"AD\",\n",
    "}\n",
    "\n",
    "for tp in range(p[\"ntp\"]):\n",
    "    train_z_d0 = [x[tp, dim0] for x in z_train if x.shape[0] > tp]\n",
    "    test_z_d0 = [x[tp, dim0] for x in z_test if x.shape[0] > tp]\n",
    "\n",
    "    train_z_d1 = [x[tp, dim1] for x in z_train if x.shape[0] > tp]\n",
    "    test_z_d1 = [x[tp, dim1] for x in z_test if x.shape[0] > tp]\n",
    "    \n",
    "    z_d0_full = z_d0_full + train_z_d0\n",
    "    z_d0_full = z_d0_full + test_z_d0\n",
    "\n",
    "    z_d1_full = z_d1_full + train_z_d1\n",
    "    z_d1_full = z_d1_full +test_z_d1\n",
    "    \n",
    "    tp_len = len(train_z_d0) + len(test_z_d0)\n",
    "    tp_full = tp_full + [tp]*tp_len\n",
    "\n",
    "    # Prepare AGE for plotting\n",
    "    color_train = [dx_dict[x[tp]] for x in Y_train[\"DX\"]]\n",
    "    color_test = [dx_dict[x[tp]] for x in Y_test[\"DX\"]]\n",
    "    #color_train = [x[tp] for x in Y_train[\"AGE\"]]\n",
    "    #color_test = [x[tp] for x in Y_test[\"AGE\"]]\n",
    "    \n",
    "    color = color + color_train + color_test\n",
    "    \n",
    "print(len(z_d0_full))\n",
    "print(len(z_d1_full))\n",
    "print(len(color))\n",
    "sns.scatterplot(x=z_d0_full, y=z_d1_full, hue=color, palette=colors, s=60)\n",
    "\n",
    "\n",
    "##Add title, x and y axis\n",
    "plt.xlabel(f\"Dim {dim0}\", size=13)\n",
    "plt.ylabel(f\"Dim {dim1}\", size=13)\n",
    "plt.title(f\"Latent space all timepoints, colord by tp\", size=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select the points and draw over it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generate the associated sample for the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare the data for brainpainter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
